using device 0 NVIDIA GeForce RTX 3090
DEVICE: cuda
client_num: 2
========== 开始训练 MVFIGN ==========
第一阶段：训练2个本地模型...
tensor(0.4187, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1918, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.2102, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.2249, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1704, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1077, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0908, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1099, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1217, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1061, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0796, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0643, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0641, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0677, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0660, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0598, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0544, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0511, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0479, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0446, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0434, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0444, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0442, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0408, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0361, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0342, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0353, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0363, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0349, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0323, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0310, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0311, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0311, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0302, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0294, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0290, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0285, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0276, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0269, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0270, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0270, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0264, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0256, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0254, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0255, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0253, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0247, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0244, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0243, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0241, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.4309, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1890, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.2137, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.2286, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1725, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1088, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0917, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1108, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1229, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1077, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0809, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0651, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0646, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0683, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0667, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0606, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0548, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0513, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0482, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0451, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0438, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0445, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0442, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0409, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0365, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0345, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0354, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0362, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0348, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0324, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0312, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0313, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0311, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0301, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0293, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0290, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0286, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0277, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0269, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0268, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0269, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0265, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0257, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0254, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0253, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0252, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0248, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0245, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0243, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.0241, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)

第一阶段训练完成，用时: 1471.79秒
tran.0.fc1.weight
tran.0.fc1.bias
tran.1.fc1.weight
tran.1.fc1.bias
classifier.fc1.weight
classifier.fc1.bias
classifier.fc2.weight
classifier.fc2.bias
classifier.layernorm.weight
classifier.layernorm.bias
tran.0.fc1.weight
tran.0.fc1.bias
tran.1.fc1.weight
tran.1.fc1.bias
classifier.fc1.weight
classifier.fc1.bias
classifier.fc2.weight
classifier.fc2.bias
classifier.layernorm.weight
classifier.layernorm.bias
第二阶段：训练全局模型...

  0%|          | 0/300 [00:00<?, ?it/s]tensor(0.1550, dtype=torch.float64) 0.049337467685252656
tensor(0.3788, dtype=torch.float64) 0.2815218636256068
tensor(0.3567, dtype=torch.float64) 0.21439259801504898
tensor(0.4047, dtype=torch.float64) 0.26997650002423246
tensor(0.3665, dtype=torch.float64) 0.3133916081873867
tensor(0.5092, dtype=torch.float64) 0.45826295137826817
tensor(0.3001, dtype=torch.float64) 0.2752324864798851
tensor(0.3592, dtype=torch.float64) 0.3350778096499023
tensor(0.3530, dtype=torch.float64) 0.30051534475386904
tensor(0.2399, dtype=torch.float64) 0.19263629293805312
tensor(0.2940, dtype=torch.float64) 0.2607621524737651
tensor(0.4600, dtype=torch.float64) 0.4070500291228305
tensor(0.5818, dtype=torch.float64) 0.5183511737679759
tensor(0.5572, dtype=torch.float64) 0.477823069348954
tensor(0.5523, dtype=torch.float64) 0.46239564687505036
tensor(0.5449, dtype=torch.float64) 0.4515238842049255
tensor(0.5547, dtype=torch.float64) 0.47829694498859726
tensor(0.5781, dtype=torch.float64) 0.5250320312445786
tensor(0.6224, dtype=torch.float64) 0.5924502762027477

  6%|▋         | 19/300 [00:00<00:01, 188.40it/s]tensor(0.6691, dtype=torch.float64) 0.6533902883628381
tensor(0.6999, dtype=torch.float64) 0.6916905173958777
tensor(0.7023, dtype=torch.float64) 0.7031279860913012
tensor(0.6827, dtype=torch.float64) 0.6978120742376261
tensor(0.6728, dtype=torch.float64) 0.696269641077859
tensor(0.7023, dtype=torch.float64) 0.7141236598264026
tensor(0.7134, dtype=torch.float64) 0.7162106955327386
tensor(0.7257, dtype=torch.float64) 0.7263314362644945
tensor(0.7060, dtype=torch.float64) 0.7062542781610115
tensor(0.6900, dtype=torch.float64) 0.6861995119396446
tensor(0.6802, dtype=torch.float64) 0.6703373470398041
tensor(0.6827, dtype=torch.float64) 0.6690089818584687
tensor(0.6888, dtype=torch.float64) 0.6744932977741853
tensor(0.6950, dtype=torch.float64) 0.6837933602537624
tensor(0.7109, dtype=torch.float64) 0.7016118740563644
tensor(0.7220, dtype=torch.float64) 0.716879229789801
tensor(0.7355, dtype=torch.float64) 0.7330590924965504
tensor(0.7442, dtype=torch.float64) 0.7429356429194149
tensor(0.7552, dtype=torch.float64) 0.7548343750292511
tensor(0.7663, dtype=torch.float64) 0.767552906386365
tensor(0.7675, dtype=torch.float64) 0.7688146596227591

 13%|█▎        | 40/300 [00:00<00:01, 195.57it/s]tensor(0.7688, dtype=torch.float64) 0.7698116197564907
tensor(0.7700, dtype=torch.float64) 0.7714488668181955
tensor(0.7626, dtype=torch.float64) 0.7648905330411517
tensor(0.7638, dtype=torch.float64) 0.7668366371083054
tensor(0.7638, dtype=torch.float64) 0.7667795203112056
tensor(0.7614, dtype=torch.float64) 0.7639253671706
tensor(0.7577, dtype=torch.float64) 0.7608625097595407
tensor(0.7577, dtype=torch.float64) 0.760722622107389
tensor(0.7503, dtype=torch.float64) 0.7531404633638275
tensor(0.7478, dtype=torch.float64) 0.7501904189319062
tensor(0.7503, dtype=torch.float64) 0.7529512598055866
tensor(0.7515, dtype=torch.float64) 0.7531915163245644
tensor(0.7552, dtype=torch.float64) 0.7565293359684148
tensor(0.7626, dtype=torch.float64) 0.7635812586322291
tensor(0.7700, dtype=torch.float64) 0.771835716670706
tensor(0.7737, dtype=torch.float64) 0.7758976371481757
tensor(0.7737, dtype=torch.float64) 0.7758317601852155
tensor(0.7749, dtype=torch.float64) 0.7770434122137968
tensor(0.7700, dtype=torch.float64) 0.7720307382562015
tensor(0.7688, dtype=torch.float64) 0.7709657606762191
tensor(0.7663, dtype=torch.float64) 0.7682622859196202

 20%|██        | 61/300 [00:00<00:01, 201.48it/s]tensor(0.7724, dtype=torch.float64) 0.7749201885370752
tensor(0.7700, dtype=torch.float64) 0.7723914324863081
tensor(0.7737, dtype=torch.float64) 0.7760876422396827
tensor(0.7724, dtype=torch.float64) 0.775307215763501
tensor(0.7675, dtype=torch.float64) 0.7703683679620128
tensor(0.7675, dtype=torch.float64) 0.7706137772364938
tensor(0.7651, dtype=torch.float64) 0.7679602523545619
tensor(0.7638, dtype=torch.float64) 0.7665777623557853
tensor(0.7675, dtype=torch.float64) 0.7701522933509896
tensor(0.7601, dtype=torch.float64) 0.7624677612752211
tensor(0.7589, dtype=torch.float64) 0.7612032372752865
tensor(0.7601, dtype=torch.float64) 0.7625814271629343
tensor(0.7626, dtype=torch.float64) 0.7646921076968268
tensor(0.7663, dtype=torch.float64) 0.7688727436897285
tensor(0.7700, dtype=torch.float64) 0.7727019030236704
tensor(0.7688, dtype=torch.float64) 0.7717587952214111
tensor(0.7712, dtype=torch.float64) 0.7741303490383037
tensor(0.7700, dtype=torch.float64) 0.7730019497976927
tensor(0.7675, dtype=torch.float64) 0.7704652001685005
tensor(0.7638, dtype=torch.float64) 0.7669062619972054
tensor(0.7577, dtype=torch.float64) 0.7603200780967372
tensor(0.7540, dtype=torch.float64) 0.7567469356717621

 28%|██▊       | 83/300 [00:00<00:01, 205.11it/s]tensor(0.7540, dtype=torch.float64) 0.7565355441283496
tensor(0.7515, dtype=torch.float64) 0.753871471075754
tensor(0.7552, dtype=torch.float64) 0.7576199579010592
tensor(0.7614, dtype=torch.float64) 0.7638439739719629
tensor(0.7626, dtype=torch.float64) 0.7656052166914266
tensor(0.7626, dtype=torch.float64) 0.7654167223112132
tensor(0.7638, dtype=torch.float64) 0.7663115199547046
tensor(0.7614, dtype=torch.float64) 0.7637725530529327
tensor(0.7601, dtype=torch.float64) 0.7623369619287754
tensor(0.7577, dtype=torch.float64) 0.7596849296925163
tensor(0.7528, dtype=torch.float64) 0.75479182859048
tensor(0.7552, dtype=torch.float64) 0.7572899308534436
tensor(0.7565, dtype=torch.float64) 0.7583913764410316
tensor(0.7638, dtype=torch.float64) 0.7660755680309134
tensor(0.7651, dtype=torch.float64) 0.7672843219168674
tensor(0.7651, dtype=torch.float64) 0.7672846407847547
tensor(0.7614, dtype=torch.float64) 0.7636138821534981
tensor(0.7589, dtype=torch.float64) 0.7612148113593397
tensor(0.7577, dtype=torch.float64) 0.7594647169521911
tensor(0.7577, dtype=torch.float64) 0.7595268748203703
tensor(0.7540, dtype=torch.float64) 0.7557327693325804
tensor(0.7552, dtype=torch.float64) 0.7572211731190424

 35%|███▌      | 105/300 [00:00<00:00, 207.66it/s]tensor(0.7540, dtype=torch.float64) 0.7560023855304708
tensor(0.7577, dtype=torch.float64) 0.7593750655255909
tensor(0.7577, dtype=torch.float64) 0.7594977938452284
tensor(0.7565, dtype=torch.float64) 0.7584384622085576
tensor(0.7540, dtype=torch.float64) 0.7558596797388855
tensor(0.7565, dtype=torch.float64) 0.7582298231710335
tensor(0.7589, dtype=torch.float64) 0.760454740609884
tensor(0.7589, dtype=torch.float64) 0.7604606493025909
tensor(0.7601, dtype=torch.float64) 0.7616191044036853
tensor(0.7589, dtype=torch.float64) 0.7605862392335655
tensor(0.7528, dtype=torch.float64) 0.7546848458417567
tensor(0.7503, dtype=torch.float64) 0.7520510931691408
tensor(0.7515, dtype=torch.float64) 0.7536332405472876
tensor(0.7491, dtype=torch.float64) 0.7510909681873775
tensor(0.7478, dtype=torch.float64) 0.749880993515704
tensor(0.7442, dtype=torch.float64) 0.745770830534239
tensor(0.7466, dtype=torch.float64) 0.748652967668384
tensor(0.7491, dtype=torch.float64) 0.7516341501796041
tensor(0.7503, dtype=torch.float64) 0.7528758524315511
tensor(0.7515, dtype=torch.float64) 0.7526495003111155
tensor(0.7478, dtype=torch.float64) 0.7478906051257805

 42%|████▏     | 126/300 [00:00<00:00, 207.38it/s]tensor(0.7540, dtype=torch.float64) 0.7541859045026834
tensor(0.7466, dtype=torch.float64) 0.7479396178879887
tensor(0.7466, dtype=torch.float64) 0.748317840599989
tensor(0.7491, dtype=torch.float64) 0.7507893167688772
tensor(0.7515, dtype=torch.float64) 0.7527892413282112
tensor(0.7528, dtype=torch.float64) 0.7537621691441315
tensor(0.7503, dtype=torch.float64) 0.7512680387069041
tensor(0.7491, dtype=torch.float64) 0.7504667088157273
tensor(0.7491, dtype=torch.float64) 0.7504388667920608
tensor(0.7540, dtype=torch.float64) 0.7548623378037546
tensor(0.7491, dtype=torch.float64) 0.7504503369251613
tensor(0.7454, dtype=torch.float64) 0.7478818304932943
tensor(0.7442, dtype=torch.float64) 0.7462604733800371
tensor(0.7503, dtype=torch.float64) 0.7512410418253707
tensor(0.7491, dtype=torch.float64) 0.7504644391348573
tensor(0.7417, dtype=torch.float64) 0.7452096721439156
tensor(0.7442, dtype=torch.float64) 0.74594877220704
tensor(0.7429, dtype=torch.float64) 0.7432630720804351
tensor(0.7442, dtype=torch.float64) 0.7454664649579965
tensor(0.7294, dtype=torch.float64) 0.7329312364437962
tensor(0.7392, dtype=torch.float64) 0.7403498833604101
tensor(0.7454, dtype=torch.float64) 0.7446079725654943

 49%|████▉     | 148/300 [00:00<00:00, 208.35it/s]tensor(0.7405, dtype=torch.float64) 0.7400263868721138
tensor(0.7343, dtype=torch.float64) 0.7371244013312881
tensor(0.7405, dtype=torch.float64) 0.7408918752598744
tensor(0.7442, dtype=torch.float64) 0.7434081909770872
tensor(0.7466, dtype=torch.float64) 0.7463869153037014
tensor(0.7429, dtype=torch.float64) 0.7446787841565717
tensor(0.7405, dtype=torch.float64) 0.7424601680891455
tensor(0.7417, dtype=torch.float64) 0.7409204585183637
tensor(0.7442, dtype=torch.float64) 0.7435792781138255
tensor(0.7392, dtype=torch.float64) 0.7410394516518336
tensor(0.7355, dtype=torch.float64) 0.737411618656628
tensor(0.7454, dtype=torch.float64) 0.7453078232825108
tensor(0.7442, dtype=torch.float64) 0.7430456618791277
tensor(0.7392, dtype=torch.float64) 0.7413268714781348
tensor(0.7392, dtype=torch.float64) 0.742175000889874
tensor(0.7392, dtype=torch.float64) 0.7390241222865525
tensor(0.7454, dtype=torch.float64) 0.7449190687797204
tensor(0.7282, dtype=torch.float64) 0.7304774568167428
tensor(0.7380, dtype=torch.float64) 0.7388206156355204
tensor(0.7343, dtype=torch.float64) 0.7340652611336799
tensor(0.7392, dtype=torch.float64) 0.7393513410247493
tensor(0.7306, dtype=torch.float64) 0.7337403234450818

 57%|█████▋    | 170/300 [00:00<00:00, 209.12it/s]tensor(0.7159, dtype=torch.float64) 0.7182653803544687
tensor(0.7355, dtype=torch.float64) 0.7359056055151286
tensor(0.7380, dtype=torch.float64) 0.7380630966765162
tensor(0.7245, dtype=torch.float64) 0.7285614378150561
tensor(0.7343, dtype=torch.float64) 0.7362505493299216
tensor(0.7368, dtype=torch.float64) 0.7364889368306106
tensor(0.7269, dtype=torch.float64) 0.7325818114760647
tensor(0.7417, dtype=torch.float64) 0.7403756204707299
tensor(0.7294, dtype=torch.float64) 0.7304111052277377
tensor(0.7282, dtype=torch.float64) 0.7321137585406867
tensor(0.7417, dtype=torch.float64) 0.7420346063341583
tensor(0.7392, dtype=torch.float64) 0.7380949027945902
tensor(0.7392, dtype=torch.float64) 0.7422319211572749
tensor(0.7380, dtype=torch.float64) 0.7412709243832273
tensor(0.7540, dtype=torch.float64) 0.7529683564649683
tensor(0.7368, dtype=torch.float64) 0.7369508670822597
tensor(0.7208, dtype=torch.float64) 0.7226849096981963
tensor(0.7380, dtype=torch.float64) 0.7373609928079896
tensor(0.7355, dtype=torch.float64) 0.735066542392679
tensor(0.7232, dtype=torch.float64) 0.7264796555628193
tensor(0.7380, dtype=torch.float64) 0.7396224215287315

 64%|██████▎   | 191/300 [00:00<00:00, 208.48it/s]tensor(0.7454, dtype=torch.float64) 0.7443987839218202
tensor(0.7343, dtype=torch.float64) 0.7358417106066578
tensor(0.7257, dtype=torch.float64) 0.7282837865362867
tensor(0.7368, dtype=torch.float64) 0.7365250636848344
tensor(0.7380, dtype=torch.float64) 0.7376946398158637
tensor(0.7232, dtype=torch.float64) 0.7274740162896122
tensor(0.7331, dtype=torch.float64) 0.7333565425364755
tensor(0.7417, dtype=torch.float64) 0.7410355551605289
tensor(0.7269, dtype=torch.float64) 0.7292947342720135
tensor(0.7380, dtype=torch.float64) 0.739309985682878
tensor(0.7429, dtype=torch.float64) 0.7450627357795188
tensor(0.7355, dtype=torch.float64) 0.7366067638354075
tensor(0.7331, dtype=torch.float64) 0.7348286199815477
tensor(0.7380, dtype=torch.float64) 0.7403740446526809
tensor(0.7429, dtype=torch.float64) 0.7432871985076435
tensor(0.7405, dtype=torch.float64) 0.7422295816205389
tensor(0.7294, dtype=torch.float64) 0.7334232747548317
tensor(0.7319, dtype=torch.float64) 0.7333043729974571
tensor(0.7454, dtype=torch.float64) 0.7441465977871747
tensor(0.7257, dtype=torch.float64) 0.7290942950379327
tensor(0.7269, dtype=torch.float64) 0.7319402346127435

 71%|███████   | 212/300 [00:01<00:00, 207.87it/s]tensor(0.7478, dtype=torch.float64) 0.745525290962508
tensor(0.7405, dtype=torch.float64) 0.741854140680117
tensor(0.7220, dtype=torch.float64) 0.7282487992639378
tensor(0.7478, dtype=torch.float64) 0.748672243426911
tensor(0.7380, dtype=torch.float64) 0.7381806955266255
tensor(0.7282, dtype=torch.float64) 0.7298113101171001
tensor(0.7319, dtype=torch.float64) 0.7330666697229462
tensor(0.7380, dtype=torch.float64) 0.7394305406300415
tensor(0.7392, dtype=torch.float64) 0.7406154506428031
tensor(0.7319, dtype=torch.float64) 0.7340845342080812
tensor(0.7306, dtype=torch.float64) 0.7331925924861766
tensor(0.7478, dtype=torch.float64) 0.7469073468077738
tensor(0.7368, dtype=torch.float64) 0.7382213766253624
tensor(0.7220, dtype=torch.float64) 0.7243411822840451
tensor(0.7442, dtype=torch.float64) 0.7453079328903455
tensor(0.7478, dtype=torch.float64) 0.7482256700770137
tensor(0.7355, dtype=torch.float64) 0.7391891852065907
tensor(0.7306, dtype=torch.float64) 0.7331376980218611
tensor(0.7380, dtype=torch.float64) 0.7373059680086858
tensor(0.7442, dtype=torch.float64) 0.7445815066294096
tensor(0.7269, dtype=torch.float64) 0.7305791989649217

 78%|███████▊  | 233/300 [00:01<00:00, 208.43it/s]tensor(0.7294, dtype=torch.float64) 0.7305583913818673
tensor(0.7245, dtype=torch.float64) 0.7245725576910927
tensor(0.7355, dtype=torch.float64) 0.7377426725552635
tensor(0.7245, dtype=torch.float64) 0.7274863395230053
tensor(0.7294, dtype=torch.float64) 0.7299900925867125
tensor(0.7269, dtype=torch.float64) 0.7278155338814282
tensor(0.7282, dtype=torch.float64) 0.7304837173815548
tensor(0.7245, dtype=torch.float64) 0.7266862032918908
tensor(0.7282, dtype=torch.float64) 0.7293557358978184
tensor(0.7331, dtype=torch.float64) 0.7343119659607628
tensor(0.7392, dtype=torch.float64) 0.7399144497100782
tensor(0.7306, dtype=torch.float64) 0.7327223224927933
tensor(0.7220, dtype=torch.float64) 0.7233192029395933
tensor(0.7282, dtype=torch.float64) 0.7284139044031083
tensor(0.7306, dtype=torch.float64) 0.733314327234629
tensor(0.7331, dtype=torch.float64) 0.7360929125607334
tensor(0.7405, dtype=torch.float64) 0.7408108791169555
tensor(0.7368, dtype=torch.float64) 0.7394924731451566
tensor(0.7282, dtype=torch.float64) 0.7301380363415793
tensor(0.7405, dtype=torch.float64) 0.7400046606354355
tensor(0.7257, dtype=torch.float64) 0.7300024594140492

 85%|████████▍ | 254/300 [00:01<00:00, 208.77it/s]tensor(0.7208, dtype=torch.float64) 0.726185139923051
tensor(0.7429, dtype=torch.float64) 0.7353593293061582
tensor(0.5916, dtype=torch.float64) 0.6214763308479835
tensor(0.5535, dtype=torch.float64) 0.5066622917641708
tensor(0.6027, dtype=torch.float64) 0.5645716944697792
tensor(0.6039, dtype=torch.float64) 0.5750874655322191
tensor(0.6445, dtype=torch.float64) 0.6073860203268505
tensor(0.5720, dtype=torch.float64) 0.5230952231982069
tensor(0.5412, dtype=torch.float64) 0.5037012160002262
tensor(0.6113, dtype=torch.float64) 0.612008802182068
tensor(0.3075, dtype=torch.float64) 0.31893753315155526
tensor(0.3419, dtype=torch.float64) 0.35196138613217076
tensor(0.5314, dtype=torch.float64) 0.5322366074111854
tensor(0.6937, dtype=torch.float64) 0.6863451957915098
tensor(0.6986, dtype=torch.float64) 0.6635021075248726
tensor(0.6974, dtype=torch.float64) 0.6590293714908593
tensor(0.6433, dtype=torch.float64) 0.6007496698999404
tensor(0.6248, dtype=torch.float64) 0.5805369932830319
tensor(0.6494, dtype=torch.float64) 0.6089935809140669
tensor(0.6851, dtype=torch.float64) 0.6462409061586009
tensor(0.7196, dtype=torch.float64) 0.6817840853433949

 92%|█████████▏| 275/300 [00:01<00:00, 208.78it/s]tensor(0.7257, dtype=torch.float64) 0.6985010831823618
tensor(0.7515, dtype=torch.float64) 0.7471806300026285
tensor(0.7454, dtype=torch.float64) 0.7456014029896493
tensor(0.7331, dtype=torch.float64) 0.7400389039106497
tensor(0.6986, dtype=torch.float64) 0.7203558321565642
tensor(0.6790, dtype=torch.float64) 0.7060752252994675
tensor(0.6839, dtype=torch.float64) 0.70607930304625
tensor(0.7073, dtype=torch.float64) 0.723459159603409
tensor(0.7294, dtype=torch.float64) 0.7382320360095783
tensor(0.7503, dtype=torch.float64) 0.754706104615236
tensor(0.7638, dtype=torch.float64) 0.7653758409078912
tensor(0.7688, dtype=torch.float64) 0.7683778738166375
tensor(0.7761, dtype=torch.float64) 0.775091768556585
tensor(0.7737, dtype=torch.float64) 0.7721696707256888
tensor(0.7761, dtype=torch.float64) 0.7750042980877201
tensor(0.7749, dtype=torch.float64) 0.7736569233775585
tensor(0.7798, dtype=torch.float64) 0.7795792725214861
tensor(0.7700, dtype=torch.float64) 0.7702250594340666
tensor(0.7663, dtype=torch.float64) 0.7669639666568818
tensor(0.7663, dtype=torch.float64) 0.7685572785131998
tensor(0.7688, dtype=torch.float64) 0.7722539091632916
tensor(0.7737, dtype=torch.float64) 0.7784809845892293

 99%|█████████▉| 297/300 [00:01<00:00, 209.34it/s]tensor(0.7651, dtype=torch.float64) 0.7706366409011397
tensor(0.7688, dtype=torch.float64) 0.7748360805070347
tensor(0.7688, dtype=torch.float64) 0.7751140291353185

100%|██████████| 300/300 [00:01<00:00, 207.18it/s]

第二阶段训练完成，用时: 1.45秒
总训练时间: 1473.24秒
  - 第一阶段: 1471.79秒
  - 第二阶段: 1.45秒
tran.0.fc1.weight Parameter containing:
tensor([[ 2.4490e-01,  7.4145e-04,  5.9772e-03,  ...,  3.9361e-03,
          7.0863e-04,  1.1475e-03],
        [ 3.2316e-03,  3.0451e-01,  3.6965e-03,  ...,  3.3191e-03,
         -1.0292e-04, -1.4854e-03],
        [ 5.8536e-03, -3.9262e-03,  3.7263e-01,  ...,  3.2595e-03,
         -8.8827e-03, -3.3606e-03],
        ...,
        [-2.5258e-03, -5.4234e-03, -3.8152e-03,  ...,  1.8954e-01,
          4.5755e-03,  3.6446e-04],
        [-3.4795e-03, -9.6148e-03, -6.2303e-03,  ...,  1.0617e-02,
          3.2606e-01,  1.2255e-03],
        [ 2.1189e-03,  3.3587e-03,  5.5865e-03,  ...,  2.6072e-03,
          7.1045e-03,  2.1499e-01]], device='cuda:0')
tran.0.fc1.bias Parameter containing:
tensor([-0.0032, -0.0057,  0.0037,  ...,  0.0035,  0.0050, -0.0042],
       device='cuda:0')
tran.1.fc1.weight Parameter containing:
tensor([[ 2.4268e-01, -1.1933e-03,  1.4839e-03,  ...,  2.1569e-04,
         -1.8805e-03,  1.1675e-03],
        [-9.2944e-04,  3.0712e-01, -8.8331e-03,  ..., -2.9688e-03,
         -7.5385e-03, -4.2592e-03],
        [ 5.2377e-03, -5.5432e-03,  3.5448e-01,  ...,  4.5745e-03,
         -1.0188e-02, -3.0508e-03],
        ...,
        [ 1.9449e-03, -1.9980e-04,  5.3977e-03,  ...,  1.8384e-01,
          1.2019e-02,  1.3697e-03],
        [-2.9276e-03, -1.2749e-02, -7.6031e-03,  ...,  3.0990e-03,
          3.2795e-01,  2.5130e-04],
        [-1.5839e-03, -1.4265e-03, -2.3034e-03,  ..., -3.2575e-03,
          2.5885e-03,  2.2358e-01]], device='cuda:0')
tran.1.fc1.bias Parameter containing:
tensor([-0.0014,  0.0050,  0.0028,  ..., -0.0051,  0.0054, -0.0002],
       device='cuda:0')
classifier.fc1.weight Parameter containing:
tensor([[-0.0533, -0.0121, -0.0352,  ..., -0.0737, -0.0429,  0.0364],
        [ 0.0535, -0.0223,  0.0285,  ...,  0.0041,  0.0083,  0.0124],
        [ 0.0110, -0.0215,  0.0416,  ...,  0.0324, -0.0072,  0.0224],
        ...,
        [-0.0086,  0.0936, -0.0670,  ..., -0.0573,  0.0414, -0.0236],
        [ 0.0098, -0.0394,  0.0661,  ..., -0.0049,  0.0089,  0.0283],
        [-0.0144,  0.0196, -0.0210,  ..., -0.0119,  0.0547, -0.0127]],
       device='cuda:0', requires_grad=True)
classifier.fc1.bias Parameter containing:
tensor([-1.1253e-01,  2.4750e-02,  7.8290e-02, -3.7899e-02, -7.2162e-03,
        -5.3700e-02, -1.1302e-02,  6.2116e-02, -1.3685e-02,  1.0161e-01,
         1.4070e-02,  6.0089e-02,  8.5094e-03,  2.9921e-02,  7.3452e-03,
         1.5711e-02,  8.9815e-03, -6.5494e-02, -1.8384e-01,  1.6226e-02,
        -4.4826e-03,  4.4318e-02,  1.9856e-02, -4.3687e-03,  2.2556e-03,
        -3.2138e-03,  3.4870e-03,  1.1012e-02, -1.8004e-02,  3.2472e-02,
         1.7408e-02,  6.5078e-02, -1.2103e-02,  9.1516e-03,  7.6164e-02,
         1.1482e-02,  3.1259e-03,  1.6883e-02, -2.7528e-02,  3.3799e-03,
        -6.0708e-03,  3.5113e-02,  2.1151e-02, -8.0685e-03,  5.8924e-03,
         2.7347e-03,  7.6256e-03, -1.5336e-02,  5.9506e-02, -6.8261e-02,
         1.2021e-02, -2.9402e-02,  6.6664e-03,  7.8317e-03, -3.6681e-03,
         1.0915e-04,  8.6226e-02,  2.6537e-02, -3.7536e-02,  7.3365e-02,
         1.3461e-02,  5.3523e-02, -4.7480e-02,  6.0489e-02,  2.2628e-02,
         1.4420e-01, -1.9575e-02,  5.5112e-03,  3.3975e-03,  1.7248e-02,
         2.3370e-02,  1.7358e-02,  3.3825e-02, -1.2495e-02,  1.8129e-02,
        -2.1951e-02, -1.0180e-01,  9.2305e-02, -1.2470e-01,  6.0779e-02,
         1.4320e-02, -2.2293e-02, -1.1597e-02,  3.0340e-03, -6.0705e-02,
        -6.1463e-03,  6.7887e-02,  3.4973e-02, -1.4252e-02, -3.8413e-02,
        -3.3108e-02, -7.1386e-03,  7.3642e-04,  1.2320e-02, -3.7652e-02,
        -2.4385e-02,  3.6991e-02, -2.6709e-03,  1.5691e-02,  2.8553e-02,
         2.2859e-02,  1.4613e-02,  2.1597e-02,  8.6667e-03,  1.9437e-02,
        -9.9166e-03, -2.9410e-02,  2.6737e-02, -4.7428e-02, -3.1283e-02,
         1.1899e-02,  2.6345e-02,  1.9026e-02, -2.0645e-02,  3.5000e-02,
         2.0376e-03,  2.9892e-02, -1.3682e-02,  3.9383e-03, -5.3667e-02,
        -1.9552e-01,  1.0167e-02, -1.3720e-02,  3.3406e-02,  1.8893e-02,
         2.9072e-02, -4.9921e-03, -4.1684e-02,  1.3796e-02,  1.1346e-02,
        -4.5320e-03,  4.1100e-02,  1.4280e-02, -5.3949e-02, -9.5242e-03,
        -1.9437e-02, -1.7512e-02,  9.8950e-03,  5.5312e-03,  1.1312e-02,
        -2.6857e-02,  2.9810e-02, -9.5335e-03,  2.6391e-02, -4.1388e-02,
        -5.1851e-02, -5.5123e-02, -1.3291e-02,  9.1075e-03,  1.9837e-02,
        -6.3169e-03,  3.3775e-03,  2.3042e-02, -2.7370e-03, -1.7065e-02,
         5.9344e-02,  6.9502e-03, -3.3037e-02,  3.5903e-03, -2.3891e-02,
         2.3023e-02,  6.2685e-02, -1.4704e-01, -2.2781e-02, -4.5222e-02,
        -1.1558e-02,  2.9159e-02, -9.9993e-03, -1.2592e-02,  2.0320e-02,
         2.8409e-02,  2.4464e-02,  2.2688e-02, -6.8970e-03, -3.7774e-02,
        -1.1402e-01,  9.6862e-03,  1.1691e-02, -5.8775e-03,  5.4000e-02,
         3.8306e-02, -3.3530e-02, -5.4879e-02,  2.1898e-02,  3.0081e-02,
        -1.0874e-01,  1.1158e-02, -3.4634e-02, -3.1378e-04,  7.5548e-03,
        -3.6595e-03,  1.9040e-02, -3.3050e-04,  4.7292e-02,  9.5226e-02,
        -1.8015e-02,  3.8743e-03,  5.2485e-03, -5.6528e-02,  8.6135e-04,
         1.5448e-02,  2.3297e-02, -4.7892e-03,  8.7080e-02, -2.8726e-02,
         1.9164e-02,  1.1052e-02,  1.7761e-02,  3.6764e-02,  2.3534e-02,
        -1.4087e-02,  2.6477e-02,  8.3612e-02, -2.7621e-02,  4.6647e-02,
         1.3246e-02, -3.7767e-04, -1.7400e-02,  1.4070e-02, -8.2327e-04,
        -1.0474e-02, -1.4810e-02,  2.1206e-02, -5.4898e-02,  8.5892e-03,
         1.9287e-02,  1.7155e-02, -7.6816e-02, -9.6585e-04,  4.1441e-02,
        -4.8997e-03, -2.5615e-04,  9.4345e-03, -9.3328e-03,  6.9904e-03,
         2.0035e-02, -8.0082e-02,  1.6472e-02, -4.3011e-03, -6.5315e-02,
         9.1720e-02,  4.0674e-02, -5.1287e-02,  1.3668e-02, -9.3515e-03,
        -4.3378e-02,  3.5539e-03, -1.6263e-02,  1.7104e-02,  6.7251e-03,
        -4.1092e-02,  1.8153e-02, -2.7044e-03,  8.9728e-03, -5.5918e-03,
        -3.4734e-02], device='cuda:0', requires_grad=True)
classifier.fc2.weight Parameter containing:
tensor([[-0.0411, -0.0648,  0.1169,  ..., -0.2138, -0.0045, -0.0321],
        [ 0.0167,  0.0928,  0.0891,  ...,  0.3003,  0.0306, -0.0105],
        [-0.0417,  0.0873,  0.0790,  ...,  0.1491, -0.1268, -0.0723],
        ...,
        [ 0.0302,  0.0133,  0.0924,  ..., -0.3429,  0.1258, -0.0213],
        [ 0.0070, -0.1267,  0.0628,  ..., -0.3867, -0.1746,  0.0531],
        [-0.0308, -0.1890,  0.0496,  ...,  0.1993, -0.2121,  0.1941]],
       device='cuda:0', requires_grad=True)
classifier.fc2.bias Parameter containing:
tensor([ 0.0461, -0.0069,  0.0049,  0.0004,  0.0402,  0.0106, -0.0014],
       device='cuda:0', requires_grad=True)
classifier.layernorm.weight Parameter containing:
tensor([0.3807, 0.6370, 0.5787, 0.8144, 0.7675, 0.7342, 0.8026, 0.5884, 0.8892,
        0.6356, 1.0473, 0.7199, 0.8577, 0.6414, 1.1367, 0.8969, 0.7566, 0.6872,
        0.2851, 0.6322, 0.9520, 0.6334, 0.6523, 0.8160, 0.8447, 0.7803, 0.8893,
        0.7258, 0.8210, 0.5310, 0.9761, 0.4816, 0.8440, 0.8278, 0.4811, 1.0299,
        0.6092, 0.8875, 0.7047, 0.7311, 0.8796, 0.8184, 0.7243, 0.7639, 0.9157,
        0.8714, 0.8743, 0.8554, 0.6055, 0.5021, 0.9849, 0.8129, 1.0382, 0.7837,
        0.8605, 1.0829, 0.4179, 0.4956, 0.7408, 0.5241, 0.6692, 0.6134, 0.7247,
        0.4727, 0.8222, 0.2868, 0.7638, 0.8518, 0.8177, 0.7974, 0.9647, 0.9320,
        0.8635, 0.8564, 1.0232, 0.8588, 0.4461, 0.4059, 0.4693, 0.6877, 1.1803,
        0.7641, 0.7210, 0.9526, 0.6330, 0.8239, 0.5155, 0.8177, 0.8737, 0.6856,
        0.7607, 0.9732, 1.0886, 1.0059, 0.8291, 0.7846, 0.7812, 0.8269, 0.9219,
        0.7676, 0.9732, 0.5738, 0.9375, 0.7019, 1.0165, 0.7608, 0.7577, 0.6981,
        0.6041, 0.8607, 0.9474, 0.9719, 0.9612, 0.7839, 0.8612, 0.8076, 0.8586,
        0.9453, 0.7328, 0.6547, 0.2923, 0.8846, 0.7468, 0.6387, 1.0641, 0.9422,
        0.7695, 0.7198, 0.8924, 1.0050, 0.8359, 0.7740, 0.8338, 0.7668, 0.8786,
        0.7458, 0.7988, 0.9170, 0.8699, 0.9727, 0.8550, 0.8375, 0.5622, 0.7592,
        0.8019, 0.6702, 0.6838, 0.8439, 0.8967, 0.7446, 0.9789, 0.8063, 0.7988,
        0.7735, 0.8369, 0.6587, 0.9654, 0.5877, 0.9036, 0.7561, 1.0884, 0.5087,
        0.5076, 0.8737, 0.6256, 0.8644, 0.6244, 0.8890, 0.7813, 0.9082, 0.7982,
        0.7927, 0.7722, 0.9523, 0.6926, 0.5913, 1.0235, 1.0072, 0.6541, 0.7064,
        0.6874, 0.6190, 0.5973, 0.7588, 0.8854, 0.5181, 0.6478, 0.7939, 1.0567,
        0.7627, 0.8957, 0.9984, 0.8168, 0.6243, 0.4597, 0.8486, 0.9893, 0.9318,
        0.6107, 0.8431, 0.7953, 0.7882, 0.8835, 0.5990, 0.7058, 0.7415, 0.9489,
        0.9681, 0.9550, 0.9640, 0.7940, 0.7460, 0.4775, 0.7771, 0.8127, 0.9892,
        0.9505, 0.8406, 1.1727, 0.9621, 0.7278, 0.8555, 0.9033, 0.6723, 0.9987,
        0.9897, 0.7424, 0.7062, 0.9108, 0.8196, 0.7509, 1.0525, 0.8499, 0.6881,
        1.0640, 0.8801, 0.6849, 1.0562, 0.8424, 0.5120, 0.3931, 0.5423, 0.6338,
        0.9522, 0.6628, 0.7686, 0.8350, 0.8017, 0.9855, 0.9850, 0.7815, 0.9137,
        0.8368, 1.0809, 0.9128, 0.7420], device='cuda:0', requires_grad=True)
classifier.layernorm.bias Parameter containing:
tensor([ 0.2996, -0.1612, -0.3027,  0.1769,  0.1160,  0.1716,  0.1257, -0.2928,
         0.1334, -0.2992, -0.0332, -0.2643, -0.1140, -0.3258, -0.0652, -0.0797,
         0.0607,  0.2102,  0.3664, -0.0899,  0.0692, -0.2186, -0.3010,  0.0996,
        -0.0225,  0.0991,  0.0239, -0.0696,  0.1183, -0.2965, -0.0416, -0.0851,
         0.1217, -0.0227, -0.3260,  0.0265,  0.0913, -0.1013, -0.0078, -0.0267,
         0.0590, -0.2074, -0.1535,  0.2062,  0.0117, -0.0223, -0.0053,  0.1122,
        -0.2374,  0.2684, -0.0778,  0.1832, -0.0312, -0.0045,  0.0735,  0.0356,
        -0.4032, -0.0638,  0.2302, -0.3342,  0.0396, -0.3093,  0.2217, -0.3303,
        -0.0781, -0.1063,  0.2029,  0.0552,  0.1013, -0.1339, -0.0886, -0.0386,
        -0.1747,  0.1085, -0.0257,  0.1645,  0.3333, -0.1094,  0.3278, -0.2405,
        -0.0947,  0.2008,  0.0034,  0.0555,  0.2210,  0.0850, -0.3144, -0.1544,
         0.0913,  0.2535,  0.1433,  0.1520, -0.0351,  0.0344,  0.1361,  0.1436,
        -0.1656,  0.0454, -0.0069, -0.1797, -0.0747, -0.1886, -0.0748, -0.0282,
        -0.0251,  0.0142,  0.2005, -0.2376,  0.2766,  0.1817, -0.0351, -0.0601,
        -0.1744,  0.1926, -0.2081,  0.0819, -0.1288,  0.0929,  0.1140,  0.2383,
         0.3361, -0.0284,  0.1925, -0.0209, -0.0969, -0.2531,  0.1607,  0.1864,
        -0.1011, -0.1116,  0.1252, -0.2242, -0.2116,  0.1549,  0.0912,  0.1727,
         0.1317, -0.0406,  0.1320, -0.0701,  0.1680, -0.2025,  0.1427, -0.2930,
         0.1669,  0.1916,  0.2072,  0.1635, -0.0609, -0.0973,  0.0878, -0.0362,
        -0.0704,  0.0469,  0.1458, -0.2113,  0.0492,  0.2053,  0.0717,  0.1466,
        -0.0621, -0.3110,  0.2862,  0.1344,  0.2949,  0.1349, -0.3249,  0.1274,
         0.0989, -0.1237, -0.1859, -0.1644, -0.1945,  0.0834,  0.1817,  0.2921,
        -0.0926, -0.0293,  0.0342, -0.2637, -0.1658,  0.0163,  0.3021, -0.1115,
        -0.1468,  0.3297,  0.0306,  0.1447, -0.0197, -0.0422,  0.1444, -0.1661,
        -0.0124, -0.2728, -0.3311,  0.1553,  0.0779,  0.0062,  0.2685, -0.0083,
        -0.0687, -0.1330,  0.1323, -0.2791,  0.1871, -0.1096, -0.0891, -0.0501,
        -0.1496, -0.0585,  0.1627, -0.1207, -0.2838,  0.1375, -0.2258, -0.0874,
         0.1015,  0.2362, -0.0115,  0.0412, -0.0342,  0.1301, -0.1300,  0.2131,
         0.0543, -0.1191, -0.1326,  0.1810,  0.1186, -0.1874,  0.0569,  0.0764,
        -0.0311,  0.2007, -0.0142, -0.0714,  0.2384, -0.0568,  0.0019,  0.3528,
        -0.3633, -0.3131,  0.2213,  0.0099,  0.1183,  0.1889,  0.0835,  0.1907,
        -0.0480, -0.0412,  0.2427, -0.0448,  0.0860, -0.1238,  0.0948,  0.2233],
       device='cuda:0', requires_grad=True)
训练时间已保存到 mvfign_training_time.txt

数据集: Cora, 客户端数: 2
第一阶段(本地训练): 1471.79秒
第二阶段(全局训练): 1.45秒
总训练时间: 1473.24秒
--------------------------------------------------
using device 0 NVIDIA GeForce RTX 3090
DEVICE: cuda
client_num: 2
MPC模式：每个客户端持有 716 个特征维度
客户端 0: 特征维度 [0:716]
客户端 1: 特征维度 [716:1433]
tensor(0.3853, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0.1359, device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>) tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)
