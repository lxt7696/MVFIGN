# mpc_utils.py - ä¿®å¤ç‰ˆï¼ˆè§£å†³ Party 1 è¿”å› None é—®é¢˜ï¼‰

import subprocess
import numpy as np
import torch
import os
import time
import re
import signal
import sys

class MPSPDZManager:
    """MP-SPDZ å®‰å…¨è®¡ç®—ç®¡ç†å™¨"""
    
    def __init__(self, party_id, mpspdz_root="/home/lxt/project/MVFIGN/MP-SPDZ"):
        self.party_id = party_id
        self.mpspdz_root = mpspdz_root
        self.player_data_dir = os.path.join(mpspdz_root, "Player-Data")

        # â­ æ·»åŠ ç¼–è¯‘ç¼“å­˜
        #self.compiled_programs = set()  # è®°å½•å·²ç¼–è¯‘çš„ç¨‹åº
        
        os.makedirs(self.player_data_dir, exist_ok=True)
        
        print(f"[Party {party_id}] MPC Manager initialized")
        print(f"  MP-SPDZ Root: {mpspdz_root}")
        print(f"  Player Data: {self.player_data_dir}")
        
    def write_inputs(self, data_dict, session_id=0):
        """å°†æ•°æ®å†™å…¥ MP-SPDZ è¾“å…¥æ–‡ä»¶"""
        input_file = os.path.join(
            self.player_data_dir, 
            f"Input-P{self.party_id}-{session_id}"
        )
        
        values = []
        
        # Party 0 æä¾› A å’Œ W
        if self.party_id == 0:
            if 'A' in data_dict and data_dict['A'] is not None:
                A = self._to_numpy(data_dict['A'])
                values.extend(A.flatten().tolist())
                print(f"[Party {self.party_id}] A shape: {A.shape}, values: {len(A.flatten())}")
            
            if 'W' in data_dict and data_dict['W'] is not None:
                W = self._to_numpy(data_dict['W'])
                values.extend(W.flatten().tolist())
                print(f"[Party {self.party_id}] W shape: {W.shape}, values: {len(W.flatten())}")
        
        # Party 1 æä¾› B
        else:
            if 'B' in data_dict and data_dict['B'] is not None:
                B = self._to_numpy(data_dict['B'])
                values.extend(B.flatten().tolist())
                print(f"[Party {self.party_id}] B shape: {B.shape}, values: {len(B.flatten())}")
        
        # å†™å…¥æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªå€¼ï¼‰
        with open(input_file, 'w') as f:
            for val in values:
                f.write(f"{float(val)}\n")
        
        print(f"[Party {self.party_id}] Wrote {len(values)} values to {input_file}")
        return len(values)
    
    def _to_numpy(self, tensor):
        """
        è½¬æ¢ä¸º numpy æ•°ç»„
        âœ… ä¿®å¤ï¼šæ·»åŠ  detach() å¤„ç†å¸¦æ¢¯åº¦çš„ Tensor
        """
        if isinstance(tensor, torch.Tensor):
            return tensor.detach().cpu().numpy()
        return np.array(tensor)
    
    def read_outputs_from_stdout(self, stdout, shape):
        """ä»æ ‡å‡†è¾“å‡ºè§£æç»“æœ"""
        if self.party_id == 1:
            # Party 1 æ˜ç¡®çŸ¥é“è‡ªå·±ä¸åº”è¯¥è·å¾—ç»“æœ
            print(f"[Party {self.party_id}] Party 1 should not receive plaintext output")
            # â­ å…³é”®ä¿®å¤ï¼šè¿”å›é›¶çŸ©é˜µè€Œä¸æ˜¯ None
            print(f"[Party {self.party_id}] Returning zero matrix of shape {shape}")
            #return torch.zeros(shape[0], shape[1])
            return torch.tensor(0.0)  # è¿”å›æ ‡é‡è€Œä¸æ˜¯çŸ©é˜µ

        print(f"\n[Party {self.party_id}] ===== PARSING OUTPUT =====")
        print(f"[Party {self.party_id}] Total stdout length: {len(stdout)} chars")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
        if len(stdout.strip()) == 0:
            print(f"[Party {self.party_id}] âš  WARNING: stdout is empty!")
            #return torch.zeros(shape[0], shape[1])
            return torch.tensor(0.0)  # è¿”å›æ ‡é‡è€Œä¸æ˜¯çŸ©é˜µ
        
        lines = stdout.strip().split('\n')
        print(f"[Party {self.party_id}] Total lines: {len(lines)}")
        
        values = []
        capturing = False
        
        for idx, line in enumerate(lines):
            line = line.strip()
            
            # æŸ¥æ‰¾ç»“æœæ ‡è®°
            if '=== RESULTS ===' in line:
                capturing = True
                print(f"\n[Party {self.party_id}] âœ“ Found RESULTS marker at line {idx}")
                continue
            
            if '=== END RESULTS ===' in line:
                capturing = False
                print(f"[Party {self.party_id}] âœ“ Found END RESULTS marker at line {idx}")
                print(f"[Party {self.party_id}] Total values captured: {len(values)}")
                break
            
            # åœ¨æ•è·åŒºåŸŸå†…è§£ææ•°å€¼
            if capturing and line:
                # è·³è¿‡æ˜æ˜¾çš„éæ•°å€¼è¡Œ
                if any(x in line for x in ['===', 'Step', 'Party', 'Reading', 'Computing', 'loaded', 'Difference', 'Matrix', 'Revealing']):
                    continue
                
                try:
                    # å°è¯•ç›´æ¥è½¬æ¢
                    val = float(line)
                    values.append(val)
                    if len(values) <= 5 or len(values) % 100 == 0:
                        print(f"[Party {self.party_id}]   Value {len(values)}: {val}")
                except ValueError:
                    # å°è¯•æå–æ•°å­—
                    match = re.search(r'[-+]?[0-9]*\.?[0-9]+([eE][-+]?[0-9]+)?', line)
                    if match:
                        val = float(match.group())
                        values.append(val)
        
        # éªŒè¯ç»“æœ - ç°åœ¨æœŸæœ›åªæœ‰ä¸€ä¸ªæ ‡é‡
        print(f"\n[Party {self.party_id}] ===== PARSING SUMMARY =====")
        print(f"[Party {self.party_id}] Expected: 1 scalar value (norm squared)")
        print(f"[Party {self.party_id}] Got: {len(values)} values")
        
        if len(values) == 0:
            print(f"\n[Party {self.party_id}] âš  WARNING: No values found")
            print(f"[Party {self.party_id}] Showing first 50 lines of stdout:")
            for i, line in enumerate(lines[:50]):
                print(f"  {i}: {line}")
            return None
        
        # åªå–ç¬¬ä¸€ä¸ªå€¼ï¼ˆèŒƒæ•°å¹³æ–¹ï¼‰
        norm_squared = values[0]
        norm = np.sqrt(norm_squared)  # å¼€æ–¹å¾—åˆ°èŒƒæ•°
        
        print(f"[Party {self.party_id}] Norm squared: {norm_squared:.4f}")
        print(f"[Party {self.party_id}] Norm (Frobenius): {norm:.4f}")
        print(f"[Party {self.party_id}] âœ“ Successfully parsed scalar")
        
        return torch.tensor(norm).float()  # è¿”å›æ ‡é‡tensor
    
    def compile_program(self, program_name="secure_matmul"):
        """ç¼–è¯‘ MPC ç¨‹åº"""
        # â­ æ£€æŸ¥æ˜¯å¦å·²ç¼–è¯‘
        #if program_name in self.compiled_programs:
         #   print(f"[Party {self.party_id}] Using cached compilation for {program_name}")
          #  return True

        compile_cmd = f"cd {self.mpspdz_root} && ./compile.py -R 64 {program_name}"
        
        print(f"[Party {self.party_id}] Compiling {program_name}...")
        
        result = subprocess.run(
            compile_cmd,
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            print(f"[Party {self.party_id}] Compilation error:")
            print(result.stderr)
            raise RuntimeError("MPC program compilation failed")

        # â­ è®°å½•ç¼–è¯‘è¿‡çš„ç¨‹åº
        #self.compiled_programs.add(program_name)        
        print(f"[Party {self.party_id}] Compilation successful")
        return True
    
    def run_party_async(self, program_name="secure_matmul", 
                       port_base=40000, timeout=10000):
        """å¼‚æ­¥è¿è¡Œ MPC å‚ä¸æ–¹"""
        run_cmd = (
            f"cd {self.mpspdz_root} && "
            f"./semi2k-party.x -p {self.party_id} "
            f"-N 2 -pn {port_base} "
            f"{program_name}"
        )
        
        print(f"[Party {self.party_id}] Running MPC...")
        print(f"  Command: {run_cmd}")
        
        if self.party_id == 0:
            print(f"[Party {self.party_id}] Starting as server (waiting for Party 1)...")
        else:
            print(f"[Party {self.party_id}] Starting as client (connecting to Party 0)...")
        
        # â­ æ”¹åŠ¨ï¼šç”¨ Popen æ›¿æ¢ runï¼Œè¿™æ ·ä¸ä¼šé˜»å¡
        process = subprocess.Popen(
            run_cmd,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        try:
            # ç­‰å¾…è¿›ç¨‹å®Œæˆï¼Œä½†æœ‰è¶…æ—¶é™åˆ¶
            stdout, stderr = process.communicate(timeout=timeout)
        except subprocess.TimeoutExpired:
            process.kill()
            stdout, stderr = process.communicate()
            raise RuntimeError(f"MPC timeout for Party {self.party_id}")
        
        if process.returncode != 0:
            print(f"[Party {self.party_id}] Execution error (returncode={process.returncode}):")
            print(f"[Party {self.party_id}] stderr:\n{stderr}")
            print(f"[Party {self.party_id}] stdout:\n{stdout}")
            raise RuntimeError("MPC execution failed")
        
        print(f"[Party {self.party_id}] MPC completed successfully")
        
        # è¿”å›ç±»ä¼¼ run() çš„ç»“æœå¯¹è±¡
        result = type('obj', (object,), {'stdout': stdout, 'stderr': stderr, 'returncode': process.returncode})()
        return result

        #result = subprocess.run(
         #   run_cmd,
          #  shell=True,
           # capture_output=True,
            #text=True,
          #  timeout=timeout
        #)
        
        #if result.returncode != 0:
         #   print(f"[Party {self.party_id}] Execution error (returncode={result.returncode}):")
          #  print(f"[Party {self.party_id}] stderr:\n{result.stderr}")
           # print(f"[Party {self.party_id}] stdout:\n{result.stdout}")
            #raise RuntimeError("MPC execution failed")
        
      #  print(f"[Party {self.party_id}] MPC completed successfully")
       # return result
    
    def secure_matrix_multiply(self, A=None, B=None, W=None, 
                          compile_once=True, session_id=0, skip_compile=False):
        """
        å®‰å…¨è®¡ç®— (A - B) * W
        â­ å…³é”®ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰åˆ†æ”¯éƒ½è¿”å›æ­£ç¡®å½¢çŠ¶çš„ tensor
        """
        print(f"\n[Party {self.party_id}] ========== secure_matrix_multiply START (session={session_id}, skip_compile={skip_compile}) ==========")
        
        # 1. å‡†å¤‡è¾“å…¥
        print(f"[Party {self.party_id}] Step 1: Preparing inputs...")
        if self.party_id == 0:
            if A is None or W is None:
                raise ValueError("Party 0 must provide A and W")
            m, n = A.shape
            print(f"[Party {self.party_id}] A shape: {A.shape}, W shape: {W.shape}")
            self.write_inputs({'A': A, 'W': W}, session_id)
        else:
            if B is None:
                raise ValueError("Party 1 must provide B")
            m, n = B.shape
            print(f"[Party {self.party_id}] B shape: {B.shape}")
            self.write_inputs({'B': B}, session_id)
        
        print(f"[Party {self.party_id}] Step 1 DONE: Inputs written")
        
        # 2. ç¼–è¯‘ç¨‹åºï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æˆ–è€…æ˜ç¡®è¦æ±‚æ—¶ç¼–è¯‘ï¼‰
        print(f"[Party {self.party_id}] Step 2: Checking compilation (skip_compile={skip_compile}, compile_once={compile_once}, session_id={session_id})...")
        if not skip_compile and (not compile_once or session_id == 0):
            if self.party_id == 0:
                print(f"[Party {self.party_id}] ğŸ”¨ Compiling MPC program (THIS MAY TAKE A WHILE)...")
                self.compile_program("secure_matmul")
                print(f"[Party {self.party_id}] âœ“ Compilation completed")
            else:
                print(f"[Party {self.party_id}] â³ Waiting for Party 0 to compile (sleeping 3 seconds)...")
                time.sleep(3)
                print(f"[Party {self.party_id}] âœ“ Wait completed")
        else:
            print(f"[Party {self.party_id}] âœ“ Skipping compilation (already compiled)")
        
        print(f"[Party {self.party_id}] Step 2 DONE: Compilation phase complete")
        
        # 3. è¿è¡Œ MPC
        print(f"[Party {self.party_id}] Step 3: Starting MPC execution...")
        result = self.run_party_async("secure_matmul", port_base=40000, timeout=10000)
        print(f"[Party {self.party_id}] Step 3 DONE: MPC execution finished")
        
        # 4. ä» stdout è¯»å–ç»“æœï¼ˆç°åœ¨æ˜¯æ ‡é‡ï¼‰
        try:
            print(f"[Party {self.party_id}] Parsing output...")
            output_scalar = self.read_outputs_from_stdout(result.stdout, (m, n))
            
            if output_scalar is None:
                # Party 1 ä¸åº”è¯¥å¾—åˆ°è¾“å‡º
                print(f"[Party {self.party_id}] No output found, returning zero scalar")
                print(f"[Party {self.party_id}] This is expected for Party 1")
                output_scalar = torch.tensor(0.0)
            
            print(f"[Party {self.party_id}] Successfully got norm scalar: {output_scalar.item():.4f}")
            return output_scalar  # è¿”å›æ ‡é‡è€Œä¸æ˜¯çŸ©é˜µ
            
        except Exception as e:
            print(f"[Party {self.party_id}] Step 4 FAILED: {e}")
            import traceback
            traceback.print_exc()
            print(f"[Party {self.party_id}] Returning zero matrix as fallback")
            print(f"[Party {self.party_id}] ========== secure_matrix_multiply END (session={session_id}) ==========\n")
            #return torch.zeros(m, n)
            return torch.tensor(0.0)  # è¿”å›æ ‡é‡è€Œä¸æ˜¯çŸ©é˜µ
    
    def secure_matrix_multiply_batched(self, A=None, B=None, W=None, batch_size=500):
        """
        åˆ†æ‰¹è®¡ç®—
        â­ ä¿®æ”¹ï¼šMPCç°åœ¨è¿”å›æ ‡é‡ï¼ˆèŒƒæ•°ï¼‰ï¼Œéœ€è¦ç´¯åŠ èŒƒæ•°å¹³æ–¹
        """
        print(f"\n[Party {self.party_id}] ========== secure_matrix_multiply_batched START ==========")
        
        if self.party_id == 0:
            A_tensor = torch.tensor(A) if not isinstance(A, torch.Tensor) else A
            W_tensor = torch.tensor(W) if not isinstance(W, torch.Tensor) else W
            m, n = A_tensor.shape
            
            print(f"[Party 0] Total samples: {m}, Feature dim: {n}")
            print(f"[Party 0] Using batch_size: {batch_size}")
            
        else:
            B_tensor = torch.tensor(B) if not isinstance(B, torch.Tensor) else B
            m, n = B_tensor.shape
            
            print(f"[Party 1] Total samples: {m}, Feature dim: {n}")
            print(f"[Party 1] Using batch_size: {batch_size}")
        
        # â­ ä¿®æ”¹ï¼šå­˜å‚¨èŒƒæ•°å¹³æ–¹ï¼ˆè€Œä¸æ˜¯çŸ©é˜µç»“æœï¼‰
        batch_norms_squared = []
        num_batches = (m + batch_size - 1) // batch_size

        # â­ å…³é”®ä¼˜åŒ–ï¼šå¦‚æœåªæœ‰1ä¸ªbatchï¼Œå°±ä¸éœ€è¦å¾ªç¯ï¼
        if num_batches == 1:
            print(f"[Party {self.party_id}] Single batch optimization: avoiding loop overhead")
            # ç›´æ¥å¤„ç†ï¼Œè·³è¿‡å¾ªç¯
            if self.party_id == 0:
                A_tensor = torch.tensor(A) if not isinstance(A, torch.Tensor) else A
                W_tensor = torch.tensor(W) if not isinstance(W, torch.Tensor) else W
                result = self.secure_matrix_multiply(A=A_tensor, W=W_tensor, session_id=0, skip_compile=False)
            else:
                B_tensor = torch.tensor(B) if not isinstance(B, torch.Tensor) else B
                result = self.secure_matrix_multiply(B=B_tensor, session_id=0, skip_compile=False)
            
            if torch.cuda.is_available():
                result = result.cuda()
            return result
        
        # å¦‚æœæœ‰å¤šä¸ªbatchæ‰è¿›å¾ªç¯
        print(f"[Party {self.party_id}] Will process {num_batches} batches")
        
        for batch_idx in range(num_batches):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, m)
            actual_batch = end_idx - start_idx
            
            print(f"\n[Party {self.party_id}] ========== BATCH {batch_idx+1}/{num_batches} START ==========")
            print(f"[Party {self.party_id}] Processing rows {start_idx}-{end_idx} (size={actual_batch})")
            
            if self.party_id == 0:
                # Party 0 å¤„ç†
                A_batch = self._to_numpy(A_tensor[start_idx:end_idx])
                
                # å¦‚æœæ‰¹æ¬¡å°äºè®¾å®šå€¼ï¼Œéœ€è¦å¡«å……
                if actual_batch < batch_size:
                    padding = np.zeros((batch_size - actual_batch, n))
                    A_batch = np.vstack([A_batch, padding])
                    print(f"[Party 0] Padded batch from {actual_batch} to {batch_size} rows")
                
                print(f"[Party 0] Calling secure_matrix_multiply with session_id={batch_idx}, skip_compile={batch_idx > 0}...")
                # â­ ä¿®æ”¹ï¼šç°åœ¨è¿”å›æ ‡é‡ï¼ˆèŒƒæ•°ï¼‰
                batch_norm = self.secure_matrix_multiply(
                    A=A_batch, W=self._to_numpy(W_tensor), 
                    session_id=batch_idx,
                    skip_compile=(batch_idx > 0)
                )
                
                # â­ ä¿®æ”¹ï¼šå­˜å‚¨èŒƒæ•°çš„å¹³æ–¹
                if batch_norm is None or not isinstance(batch_norm, torch.Tensor):
                    print(f"[Party 0] WARNING: batch_norm is None or not tensor, using 0")
                    batch_norms_squared.append(torch.tensor(0.0))
                else:
                    batch_norms_squared.append(batch_norm ** 2)
                    print(f"[Party 0] Batch {batch_idx} norm: {batch_norm.item():.4f}")
                
                print(f"[Party 0] ========== BATCH {batch_idx+1}/{num_batches} DONE ==========\n")
                
            else:
                # Party 1 å¤„ç†
                B_batch = self._to_numpy(B_tensor[start_idx:end_idx])
                
                # åŒæ ·éœ€è¦å¡«å……
                if actual_batch < batch_size:
                    padding = np.zeros((batch_size - actual_batch, n))
                    B_batch = np.vstack([B_batch, padding])
                    print(f"[Party 1] Padded batch from {actual_batch} to {batch_size} rows")
                
                print(f"[Party 1] Calling secure_matrix_multiply with session_id={batch_idx}, skip_compile={batch_idx > 0}...")
                # â­ ä¿®æ”¹ï¼šç°åœ¨è¿”å›æ ‡é‡ï¼ˆèŒƒæ•°ï¼‰
                batch_norm = self.secure_matrix_multiply(
                    B=B_batch, 
                    session_id=batch_idx,
                    skip_compile=(batch_idx > 0)
                )
                
                # â­ ä¿®æ”¹ï¼šParty 1ä¹Ÿå­˜å‚¨ï¼ˆè™½ç„¶åº”è¯¥æ˜¯0ï¼‰
                if batch_norm is None or not isinstance(batch_norm, torch.Tensor):
                    batch_norms_squared.append(torch.tensor(0.0))
                else:
                    batch_norms_squared.append(batch_norm ** 2)
                
                print(f"[Party 1] ========== BATCH {batch_idx+1}/{num_batches} DONE ==========\n")
        
        # â­ ä¿®æ”¹ï¼šåˆå¹¶ç»“æœ - ç´¯åŠ æ‰€æœ‰æ‰¹æ¬¡çš„èŒƒæ•°å¹³æ–¹ï¼Œç„¶åå¼€æ–¹
        print(f"[Party {self.party_id}] Merging {len(batch_norms_squared)} batch results...")
        
        total_norm_squared = sum(batch_norms_squared)
        final_norm = torch.sqrt(total_norm_squared)
        
        print(f"[Party {self.party_id}] Total norm squared: {total_norm_squared.item():.4f}")
        print(f"[Party {self.party_id}] Final Frobenius norm: {final_norm.item():.4f}")
        
        # ç§»åˆ° GPU
        if torch.cuda.is_available():
            final_norm = final_norm.cuda()
            print(f"[Party {self.party_id}] Moved result to GPU")
        
        print(f"[Party {self.party_id}] ========== secure_matrix_multiply_batched END ==========\n")
        return final_norm  # â­ ä¿®æ”¹ï¼šè¿”å›æ ‡é‡è€Œä¸æ˜¯çŸ©é˜µ
    
    def cleanup(self, session_id=0):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        files = [
            f"Input-P{self.party_id}-{session_id}",
            f"Output-P{self.party_id}-{session_id}"
        ]
        
        for fname in files:
            fpath = os.path.join(self.player_data_dir, fname)
            if os.path.exists(fpath):
                os.remove(fpath)
                print(f"[Party {self.party_id}] Removed {fname}")


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--party', type=int, required=True, choices=[0, 1])
    parser.add_argument('--m', type=int, default=100)
    parser.add_argument('--n', type=int, default=500)
    parser.add_argument('--batch_size', type=int, default=100)
    args = parser.parse_args()
    
    print(f"\n{'='*60}")
    print(f"Testing BATCHED MPC as Party {args.party}")
    print(f"Matrix size: {args.m}x{args.n}")
    print(f"Batch size: {args.batch_size}")
    print(f"IMPORTANT: Run Party 0 first, then Party 1 within 5 seconds!")
    print(f"{'='*60}\n")
    
    mpc = MPSPDZManager(party_id=args.party)
    
    try:
        if args.party == 0:
            # Party 0
            A = torch.randn(args.m, args.n)
            W = torch.randn(args.n, args.n)
            print(f"Party 0 - Generated A: {A.shape}")
            print(f"Party 0 - Generated W: {W.shape}")
            
            result = mpc.secure_matrix_multiply_batched(
                A=A, W=W, batch_size=args.batch_size
            )
            #print(f"\nParty 0 - Final Result shape: {result.shape}")
            #print(f"Party 0 - Result norm: {torch.norm(result):.4f}")
            print(f"\nParty 0 - Final Result (scalar norm): {result.item():.4f}")
            print(f"Party 0 - Result type: {type(result)}")
            
        else:
            # Party 1
            B = torch.randn(args.m, args.n)
            print(f"Party 1 - Generated B: {B.shape}")
            
            result = mpc.secure_matrix_multiply_batched(
                B=B, batch_size=args.batch_size
            )
            # â­ ä¿®å¤å Party 1 ä¹Ÿæœ‰ shape å±æ€§
            #print(f"\nParty 1 - Successfully got result shape: {result.shape}")
            print(f"\nParty 1 - Successfully got result (should be 0): {result.item():.4f}")
        
        print(f"\n{'='*60}")
        print("Test PASSED!")
        print(f"{'='*60}\n")
        
    except Exception as e:
        print(f"\n{'='*60}")
        print(f"Test FAILED: {e}")
        import traceback
        traceback.print_exc()
        print(f"{'='*60}\n")
        raise